{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_on = {\n",
    "    'beat':'dataset-baru/beat-nyala', 'bull':'dataset-baru/bull-nyala', 'cbr':'dataset-baru/cbr-nyala', \n",
    "    'mio':'dataset-baru/mio-nyala', 'mio2':'dataset-baru/mio2-nyala', 'scoopy':'dataset-baru/scoopy-nyala', \n",
    "    'supra':'dataset-baru/supra-nyala'\n",
    "}\n",
    "\n",
    "dir_off = {\n",
    "    'beat':'dataset-baru/beat-mati', 'bull':'dataset-baru/bull-mati', 'cbr':'dataset-baru/cbr-mati', \n",
    "    'mio':'dataset-baru/mio-mati', 'mio2':'dataset-baru/mio2-mati', 'scoopy':'dataset-baru/scoopy-mati', \n",
    "    'supra':'dataset-baru/supra-mati'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_on = f\"{dir_on['beat']}/1.jpg\"\n",
    "beat_off = f\"{dir_off['beat']}/1.jpg\"\n",
    "image_paths = [beat_on, beat_off]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat jendela gambar\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loop melalui path file gambar dan menampilkannya\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # print(image_path)\n",
    "    plt.subplot(1, len(image_paths), i + 1)  # 1 baris, n kolom\n",
    "    image = cv2.imread(image_path)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')  # Matikan tanda sumbu x dan y\n",
    "\n",
    "# Tampilkan semua gambar dalam satu jendela tampilan\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_beat_on = cv2.imread(beat_on)\n",
    "img_beat_off = cv2.imread(beat_off)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_beat_on, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off') \n",
    "plt.show()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_beat_off, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_beat_on = imread(beat_on)\n",
    "img_beat_off = imread(beat_off)\n",
    "\n",
    "plt.imshow(img_beat_on)\n",
    "plt.axis('off') \n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img_beat_off)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(img_beat_on, cv2.COLOR_BGR2HSV)\n",
    "plt.imshow(cv2.cvtColor(hsv_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')  # Menghilangkan sumbu koordinat\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan rentang warna putih dalam HSV\n",
    "lower_white = np.array([0, 0, 200])\n",
    "upper_white = np.array([180, 30, 255])\n",
    "\n",
    "# Buat mask dengan rentang warna putih\n",
    "mask = cv2.inRange(hsv_image, lower_white, upper_white)\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')  # Menghilangkan sumbu koordinat\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coba detek motor dengan YOLO\n",
    "link : https://www.freecodecamp.org/news/how-to-detect-objects-in-images-using-yolov8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(\"yolov8s-seg.pt\")\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "#segmentation model small, n = nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 person, 1 motorcycle, 278.0ms\n",
      "Speed: 10.0ms preprocess, 278.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: ultralytics.engine.results.Masks object\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "orig_img: array([[[  8,  14,  10],\n",
       "        [  9,  15,  11],\n",
       "        [  7,  16,  11],\n",
       "        ...,\n",
       "        [116, 119, 108],\n",
       "        [121, 123, 110],\n",
       "        [140, 142, 129]],\n",
       "\n",
       "       [[  6,  12,   8],\n",
       "        [  7,  13,   9],\n",
       "        [  5,  14,   9],\n",
       "        ...,\n",
       "        [118, 122, 108],\n",
       "        [129, 131, 118],\n",
       "        [149, 151, 138]],\n",
       "\n",
       "       [[  5,  11,   7],\n",
       "        [  6,  12,   8],\n",
       "        [  5,  14,   9],\n",
       "        ...,\n",
       "        [127, 129, 115],\n",
       "        [134, 136, 122],\n",
       "        [149, 151, 137]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 11,  25,  25],\n",
       "        [  9,  25,  25],\n",
       "        [  7,  25,  25],\n",
       "        ...,\n",
       "        [ 31,  40,  49],\n",
       "        [ 33,  42,  51],\n",
       "        [ 39,  48,  57]],\n",
       "\n",
       "       [[  7,  21,  21],\n",
       "        [ 11,  25,  25],\n",
       "        [ 12,  28,  28],\n",
       "        ...,\n",
       "        [ 34,  41,  51],\n",
       "        [ 33,  40,  50],\n",
       "        [ 33,  40,  50]],\n",
       "\n",
       "       [[ 15,  27,  27],\n",
       "        [  8,  22,  22],\n",
       "        [ 11,  27,  27],\n",
       "        ...,\n",
       "        [ 34,  41,  51],\n",
       "        [ 34,  41,  51],\n",
       "        [ 30,  37,  47]]], dtype=uint8)\n",
       "orig_shape: (4032, 3024)\n",
       "path: 'image0.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 10.000228881835938, 'inference': 278.00822257995605, 'postprocess': 6.995201110839844}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(img_beat_on)\n",
    "result = results[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(result.boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[1.22293e+03, 6.14840e+02, 1.30990e+03, 7.93553e+02, 4.31682e-01, 0.00000e+00]])\n",
       "cls: tensor([0.])\n",
       "conf: tensor([0.43168])\n",
       "data: tensor([[1.22293e+03, 6.14840e+02, 1.30990e+03, 7.93553e+02, 4.31682e-01, 0.00000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (4032, 3024)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[1266.41064,  704.19666,   86.96960,  178.71362]])\n",
       "xywhn: tensor([[0.41879, 0.17465, 0.02876, 0.04432]])\n",
       "xyxy: tensor([[1222.92590,  614.83984, 1309.89551,  793.55347]])\n",
       "xyxyn: tensor([[0.40441, 0.15249, 0.43317, 0.19681]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = result.boxes[0]\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1 = result.boxes[0]\n",
    "box2 = result.boxes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: tensor([0.])\n",
      "Coordinates: tensor([[1222.92590,  614.83984, 1309.89551,  793.55347]])\n",
      "Probability: tensor([0.43168])\n"
     ]
    }
   ],
   "source": [
    "print(\"Object type:\", box1.cls)\n",
    "print(\"Coordinates:\", box1.xyxy)\n",
    "print(\"Probability:\", box1.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: tensor([3.])\n",
      "Coordinates: tensor([[1470.78833, 1128.69373, 1928.36133, 1995.18884]])\n",
      "Probability: tensor([0.35642])\n"
     ]
    }
   ],
   "source": [
    "print(\"Object type:\", box2.cls)\n",
    "print(\"Coordinates:\", box2.xyxy)\n",
    "print(\"Probability:\", box2.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: 0.0\n",
      "Coordinates: [1222.9259033203125, 614.83984375, 1309.8955078125, 793.553466796875]\n",
      "Probability: 0.4316817820072174\n"
     ]
    }
   ],
   "source": [
    "cords = box1.xyxy[0].tolist()\n",
    "class_id = box1.cls[0].item()\n",
    "conf = box1.conf[0].item()\n",
    "print(\"Object type:\", class_id)\n",
    "print(\"Coordinates:\", cords)\n",
    "print(\"Probability:\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: person\n",
      "Coordinates: [1223, 615, 1310, 794]\n",
      "Probability: 0.43\n"
     ]
    }
   ],
   "source": [
    "cords = box.xyxy[0].tolist()\n",
    "cords = [round(x) for x in cords]\n",
    "class_id = result.names[box.cls[0].item()]\n",
    "conf = round(box.conf[0].item(), 2)\n",
    "print(\"Object type:\", class_id)\n",
    "print(\"Coordinates:\", cords)\n",
    "print(\"Probability:\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\whisn/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"torchvision>=0.8.1\" not found, attempting AutoUpdate...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.1+cu117)\n",
      "Requirement already satisfied: numpy in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from torchvision>=0.8.1) (1.25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from torchvision>=0.8.1) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision>=0.8.1) (2.0.0+cu117)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision>=0.8.1) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision>=0.8.1) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision>=0.8.1) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision>=0.8.1) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from torch==2.0.0->torchvision>=0.8.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision>=0.8.1) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision>=0.8.1) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision>=0.8.1) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision>=0.8.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision>=0.8.1) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\whisn\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->torch==2.0.0->torchvision>=0.8.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0->torchvision>=0.8.1) (1.2.1)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per C:\\Users\\whisn\\.cache\\torch\\hub\\ultralytics_yolov5_master\\requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5  2023-3-27 Python-3.9.16 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)\n",
    "# model = torch.load(\"yolov5n.pt\")\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "# model = torch.load(\"yolov5s.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1.46585e+03, 1.15177e+03, 1.94091e+03, 1.97994e+03, 6.80087e-01, 3.00000e+00],\n",
      "        [1.22097e+03, 6.05621e+02, 1.32310e+03, 7.87416e+02, 3.99865e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_run',\n",
       " 'crop',\n",
       " 'files',\n",
       " 'ims',\n",
       " 'n',\n",
       " 'names',\n",
       " 'pandas',\n",
       " 'pred',\n",
       " 'print',\n",
       " 'render',\n",
       " 's',\n",
       " 'save',\n",
       " 'show',\n",
       " 't',\n",
       " 'times',\n",
       " 'tolist',\n",
       " 'xywh',\n",
       " 'xywhn',\n",
       " 'xyxy',\n",
       " 'xyxyn']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = ['dataset-baru/beat-nyala/1.jpg']\n",
    "\n",
    "# Call the detect() method on the model\n",
    "results = model(imgs)\n",
    "\n",
    "# Print the results\n",
    "print(results.pred)\n",
    "# len(results)\n",
    "dir(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\whisn\\Downloads\\Whisnumurty\\Kuliah\\Penelitian\\Penelitian Deteksi Lampu Sepeda Motor\\detect-lamp\\main-terang.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Loop through the detected objects in the results\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpred[\u001b[39m0\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Check if the label of the detected object is \"motorcycle\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m result[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmotorcycle\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m# Extract the coordinates of the detected motorcycle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         x1, y1, x2, y2 \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whisn/Downloads/Whisnumurty/Kuliah/Penelitian/Penelitian%20Deteksi%20Lampu%20Sepeda%20Motor/detect-lamp/main-terang.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# Crop the motorcycle from the image (assuming you have the original image)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "# Loop through the detected objects in the results\n",
    "for result in results.pred[0]:\n",
    "    # Check if the label of the detected object is \"motorcycle\"\n",
    "    if result['label'] == 'motorcycle':\n",
    "        # Extract the coordinates of the detected motorcycle\n",
    "        x1, y1, x2, y2 = result['bbox']\n",
    "        \n",
    "        # Crop the motorcycle from the image (assuming you have the original image)\n",
    "        motorcycle_img = img_beat_on[y1:y2, x1:x2]\n",
    "        \n",
    "        # Do further processing on the motorcycle image if needed\n",
    "        # For example, you can save it or perform additional analysis\n",
    "\n",
    "# You can also print the number of detected motorcycles\n",
    "num_motorcycles = sum(1 for result in results.pred[0] if result['label'] == 'motorcycle')\n",
    "print(f\"Number of motorcycles detected: {num_motorcycles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465.852539</td>\n",
       "      <td>1151.767944</td>\n",
       "      <td>1940.908813</td>\n",
       "      <td>1979.937988</td>\n",
       "      <td>0.680087</td>\n",
       "      <td>3</td>\n",
       "      <td>motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220.966187</td>\n",
       "      <td>605.621155</td>\n",
       "      <td>1323.097656</td>\n",
       "      <td>787.416138</td>\n",
       "      <td>0.399865</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xmin         ymin         xmax         ymax  confidence  class  \\\n",
       "0  1465.852539  1151.767944  1940.908813  1979.937988    0.680087      3   \n",
       "1  1220.966187   605.621155  1323.097656   787.416138    0.399865      0   \n",
       "\n",
       "         name  \n",
       "0  motorcycle  \n",
       "1      person  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "# results.print()\n",
    "# results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
