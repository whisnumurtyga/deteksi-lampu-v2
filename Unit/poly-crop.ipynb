{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from yolo_segmentation import YOLOSegmentation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rszImg(image, rate):\n",
    "    h, w, _ = image.shape\n",
    "    new_h, new_w = (int(h*rate), int(w*rate))\n",
    "    image = cv2.resize(image, (new_w, new_h))\n",
    "    return image\n",
    "\n",
    "def cropPoly(img, bbox, seg):\n",
    "    (x, y, x2, y2) = bbox\n",
    "    # Create a mask of the same size as the image\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    # Convert the seg (polygon) into a NumPy array of type int32\n",
    "    points = np.array(seg, dtype=np.int32)\n",
    "\n",
    "    # Fill the mask with a white polygon based on the points\n",
    "    cv2.fillPoly(mask, [points], (255, 255, 255))\n",
    "\n",
    "    # Bitwise AND the mask with the original image to get the cropped region\n",
    "    cropped_motorcycle = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    # Crop the region inside the bounding box\n",
    "    cropped_motorcycle = cropped_motorcycle[y:y2, x:x2]\n",
    "    \n",
    "    return cropped_motorcycle\n",
    "\n",
    "def segmentMotorcycle(path):\n",
    "    global ys\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    img = rszImg(img, 0.25)\n",
    "    bboxes, classes, class_names, segmentation, scores = ys.detect(img)\n",
    "\n",
    "    cropped_motorcycle_regions = []\n",
    "    n = 0\n",
    "\n",
    "    for bbox, class_id, seg, score in zip(bboxes, classes, segmentation, scores):\n",
    "        # print(\"bbox:\", bbox, \" class_id:\", class_id, \" seg:\", seg, \" score:\", score)\n",
    "        if class_names[class_id] == 'motorcycle':\n",
    "            (x, y, x2, y2) = bbox\n",
    "\n",
    "            cropped_motorcycle = cropPoly(img, bbox, seg)\n",
    "            cropped_motorcycle_regions.append(cropped_motorcycle)\n",
    "\n",
    "            # Draw the bounding box, polyline, and class name on the original image\n",
    "            cv2.rectangle(img, (x, y), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.polylines(img, [seg], True, (255, 0, 0), 2)\n",
    "            cv2.putText(img, str(class_names[class_id]), (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "            \n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "global ys\n",
    "ys = YOLOSegmentation('../learn/yolov8-polylines/yolov8n-seg.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_nyala = '../dataset-baru/scoopy-mati/52.jpg'\n",
    "# path_nyala = 'awikwok.jpg'\n",
    "path_mati = '../dataset-baru/beat-mati/0.jpg'\n",
    "\n",
    "\n",
    "# flag = 'nyala'\n",
    "# img = cv2.imread(path_nyala)\n",
    "flag = 'mati'\n",
    "img = cv2.imread(path_nyala)\n",
    "\n",
    "# img = cv2.resize(img, None, fx=0.2, fy=0.2)\n",
    "img = rszImg(img, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 2 persons, 1 car, 1 motorcycle, 515.7ms\n",
      "Speed: 6.0ms preprocess, 515.7ms inference, 20.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "WARNING  'Masks.segments' is deprecated. Use 'Masks.xyn' for segments (normalized) and 'Masks.xy' for segments (pixels) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       0.85        0.33        0.32        0.31]\n"
     ]
    }
   ],
   "source": [
    "# Segmentation\n",
    "# ys = YOLOSegmentation('../../yolov8n-seg.pt')\n",
    "bboxes, classes, class_names, segmentation, scores = ys.detect(img)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_motorcycle_regions = []\n",
    "n = 0\n",
    "\n",
    "for bbox, class_id, seg, score in zip(bboxes, classes, segmentation, scores):\n",
    "    # print(\"bbox:\", bbox, \" class_id:\", class_id, \" seg:\", seg, \" score:\", score)\n",
    "    if class_names[class_id] == 'motorcycle':\n",
    "        (x, y, x2, y2) = bbox\n",
    "\n",
    "        cropped_motorcycle = cropPoly(img, bbox, seg)\n",
    "        cropped_motorcycle_regions.append(cropped_motorcycle)\n",
    "\n",
    "        # Draw the bounding box, polyline, and class name on the original image\n",
    "        cv2.rectangle(img, (x, y), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.polylines(img, [seg], True, (255, 0, 0), 2)\n",
    "        cv2.putText(img, str(class_names[class_id]), (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(cropped_motorcycle_regions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cropped motorcycle regions or do further processing\n",
    "for i, cropped_motorcycle in enumerate(cropped_motorcycle_regions):\n",
    "    if flag == 'nyala':\n",
    "        cv2.imwrite(f'result/nyala/{i}.jpg', cropped_motorcycle)\n",
    "    else :\n",
    "        cv2.imwrite(f'result/mati/{i}.jpg', cropped_motorcycle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 2 persons, 1 car, 1 motorcycle, 547.3ms\n",
      "Speed: 10.1ms preprocess, 547.3ms inference, 21.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "WARNING  'Masks.segments' is deprecated. Use 'Masks.xyn' for segments (normalized) and 'Masks.xy' for segments (pixels) instead.\n"
     ]
    }
   ],
   "source": [
    "segmentMotorcycle(path_nyala)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
